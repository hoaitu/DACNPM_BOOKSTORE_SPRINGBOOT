<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Data Gateways in the Cloud Native Era</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/r9Na-7W7j-Y/data-gateways-of-future.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2021/05/data-gateways-of-future.html</id><updated>2021-05-29T11:52:00Z</updated><content type="html">These days, there is a lot of excitement around 12-factor apps, microservices, and service mesh, but not so much around cloud-native data. The number of conference talks, blog posts, best practices, and purpose-built tools around cloud-native data access is relatively low. One of the main reasons for this is because most data access technologies are architectured and created in a stack that favors static environments rather than the dynamic nature of cloud environments and Kubernetes. In this article, we will explore the different categories of data gateways, from more monolithic to ones designed for the cloud and Kubernetes. We will see what are the technical challenges introduced by the Microservices architecture and how data gateways can complement API gateways to address these challenges in the Kubernetes era. APPLICATION ARCHITECTURE EVOLUTIONS Let’s start with what has been changing in the way we manage code and the data in the past decade or so. I still remember the time when I started my IT career by creating frontends with Servlets, JSP, and JSFs. In the backend, EJBs, SOAP, server-side session management, was the state of art technologies and techniques. But things changed rather quickly with the introduction of REST and popularization of Javascript. REST helped us decouple frontends from backends through a uniform interface and resource-oriented requests. It popularized stateless services and enabled response caching, by moving all client session state to clients, and so forth. This new architecture was the answer to the huge scalability demands of modern businesses. A similar change happened with the backend services through the Microservices movement. Decoupling from the frontend was not enough, and the monolithic backend had to be decoupled into bounded context enabling independent fast-paced releases. These are examples of how architectures, tools, and techniques evolved pressured by the business needs for fast software delivery of planet-scale applications. That takes us to the data layer. One of the existential motivations for microservices is having independent data sources per service. If you have microservices touching the same data, that sooner or later introduces coupling and limits independent scalability or releasing. It is not only an independent database but also a heterogeneous one, so every microservice is free to use the database type that fits its needs. Application architecture evolution brings new challenges While decoupling frontend from backend and splitting monoliths into microservices gave the desired flexibility, it created challenges not-present before. Service discovery and load balancing, network-level resilience, and observability turned into major areas of technology innovation addressed in the years that followed. Similarly, creating a database per microservice, having the freedom and technology choice of different datastores is a challenge. That shows itself more and more recently with the explosion of data and the demand for accessing data not only by the services but other real-time reporting and AI/ML needs. THE RISE OF API GATEWAYS With the increasing adoption of Microservices, it became apparent that operating such an architecture is hard. While having every microservice independent sounds great, it requires tools and practices that we didn’t need and didn’t have before. This gave rise to more advanced release strategies such as blue/green deployments, canary releases, dark launches. Then that gave rise to fault injection and automatic recovery testing. And finally, that gave rise to advanced network telemetry and tracing. All of these created a whole new layer that sits between the frontend and the backend. This layer is occupied primarily with API management gateways, service discovery, and service mesh technologies, but also with tracing components, application load balancers, and all kinds of traffic management and monitoring proxies. This even includes projects such as Knative with activation and scaling-to-zero features driven by the networking activity. With time, it became apparent that creating microservices at a fast pace, operating microservices at scale requires tooling we didn’t need before. Something that was fully handled by a single load balancer had to be replaced with a new advanced management layer. A new technology layer, a new set of practices and techniques, and a new group of users responsible were born. THE CASE FOR DATA GATEWAYS Microservices influence the data layer in two dimensions. First, it demands an independent database per microservice. From a practical implementation point of view, this can be from an independent database instance to independent schemas and logical groupings of tables. The main rule here is, only one microservice owns and touches a dataset. And all data is accessed through the APIs or Events of the owning microservice. The second way a microservices architecture influenced the data layer is through datastore proliferation. Similarly, enabling microservices to be written in different languages, this architecture allows the freedom for every microservices-based system to have a  persistence layer. With this freedom, one microservice can use a relational database, another one can use a document database, and the third microservice one uses an in-memory key-value store. While microservices allow you all that freedom, again it comes at a cost. It turns out operating a large number of datastore comes at a cost that existing tooling and practices were not prepared for. In the modern digital world, storing data in a reliable form is not enough. Data is useful when it turns into insights and for that, it has to be accessible in a controlled form by many. AI/ML experts, data scientists, business analysts, all want to dig into the data, but the application-focused microservices and their data access patterns are not  for these data-hungry demands. API and Data gateways offering similar capabilities at different layers This is where data gateways can help you. A data gateway is like an API gateway, but it understands and acts on the physical data layer rather than the networking layer. Here are a few areas where data gateways differ from API gateways. ABSTRACTION An API gateway can hide implementation endpoints and help upgrade and rollback services without affecting service consumers. Similarly, a data gateway can help abstract a physical data source, its specifics, and help alter, migrate, decommission, without affecting data consumers. SECURITY An API manager secures resource endpoints based on HTTP methods. A service mesh secures based on network connections. But none of them can understand and secure the data and its shape that is passing through them. A data gateway, on the other hand, understands the different data sources and the data model and acts on them. It can apply RBAC per data row and column, filter, obfuscate, and sanitize the individual data elements whenever necessary. This is a more fine-grained security model than networking or API level security of API gateways. SCALING API gateways can do service discovery, load-balancing, and assist the scaling of services through an orchestrator such as Kubernetes. But they cannot scale data. Data can scale only through replication and caching. Some data stores can do replication in cloud-native environments but not all. Purpose-built tools, such as , can perform change data capture from the transaction logs of data stores and enable data replication for scaling and other use cases. A data gateway, on the other hand, can speed-up access to all kinds of data sources by caching data and providing materialized views. It can understand the queries, optimize them based on the capabilities of the data source, and produce the most performant execution plan. The combination of materialized views and the stream nature of change data capture would be the ultimate data scaling technique, but there are no known cloud-native implementations of this yet. FEDERATION In API management, response composition is a common technique for aggregating data from multiple different systems. In the data space, the same technique is referred to as heterogeneous data federation. Heterogeneity is the degree of differentiation in various data sources such as network protocols, query languages, query capabilities, data models, error handling, transaction semantics, etc. A data gateway can accommodate all of these differences as a seamless, transparent data-federation layer. SCHEMA-FIRST API gateways allow contract-first service and client development with specifications such as OpenAPI. Data gateways allow schema-first data consumption based on the SQL standard. A SQL schema for data modeling is the OpenAPI equivalent of APIs. MANY SHADES OF DATA GATEWAYS In this article, I use the terms API and data gateways loosely to refer to a set of capabilities. There are many types of API gateways such as API managers, load balancers, service mesh, service registry, etc. It is similar to data gateways, where they range from huge monolithic data virtualization platforms that want to do everything, to data federation libraries, from purpose-built cloud services to end-user query tools. Let’s explore the different types of data gateways and see which fit the definition of “a cloud-native data gateway.” When I say a cloud-native data gateway, I mean a containerized first-class Kubernetes citizen. I mean a gateway that is open source, using open standards; a component that can be deployed on hybrid/multi-cloud infrastructures, work with different data sources, data formats, and applicable for many use cases. CLASSIC DATA VIRTUALIZATION PLATFORMS In the very first category of data gateways, are the traditional data virtualization platforms such as  and . While these are the most feature-laden data platforms, they tend to do too much and want to be everything from API management, to metadata management, data cataloging, environment management, deployment, configuration management, and whatnot. From an architectural point of view, they are very much like the old ESBs, but for the data layer. You may manage to put them into a container, but it is hard to put them into the cloud-native citizen category. DATABASES WITH DATA FEDERATION CAPABILITIES Another emerging trend is the fact that databases, in addition to storing data, are also starting to act as data federation gateways and allowing access to external data. For example, PostgreSQL  the ANSI SQL/MED specification for a standardized way of handling access to remote objects from SQL databases. That means remote data stores, such as SQL, NoSQL, File, LDAP, Web, Big Data, can all be accessed as if they were tables in the same PostgreSQL database. SQL/MED stands for Management of External Data, and it is also implemented by MariaDB  engine, , Teiid project discussed below, and a few . Starting in SQL Server 2019, you can now query external data sources without moving or copying the data. The  engine of SQL Server instance to process Transact-SQL queries to access external data in SQL Server, Oracle, Teradata, and MongoDB. GRAPHQL DATA BRIDGES Compared to the traditional data virtualization, this is a new category of data gateways focused around the fast web-based data access. The common thing around , , , is that they focus on GraphQL data access by offering a lightweight abstraction on top of a few data sources. This is a fast-growing category specialized for enabling rapid web-based development of data-driven applications rather than BI/AI/ML use cases. OPEN-SOURCE DATA GATEWAYS  is a schema-free SQL query engine for NoSQL databases and file systems. It offers JDBC and ODBC access to business users, analysts, and data scientists on top of data sources that don’t support such APIs. Again, having uniform SQL based access to disparate data sources is the driver. While Drill is highly scalable, it relies on Hadoop or Apache Zookeeper’s kind of infrastructure which shows its age.  is a mature data federation engine sponsored by Red Hat. It uses the SQL/MED specification for defining the virtual data models and relies on the Kubernetes Operator model for the building, deployment, and management of its runtime. Once deployed, the runtime can scale as any other stateless cloud-native workload on Kubernetes and integrate with other cloud-native projects. For example, it can use  for single sign-on and data roles,  for distributed caching needs, export metrics and register with Prometheus for monitoring, Jaeger for tracing, and even with for API management. But ultimately, Teiid runs as a single Spring Boot application acting as a data proxy and integrating with other best-of-breed services on Openshift rather than trying to reinvent everything from scratch. Architectural overview of Teiid data gateway On the client-side, Teiid offers standard SQL over JDBC/ODBC and Odata APIs. Business users, analysts, and data scientists can use standard BI/analytics tools such as Tableau, MicroStrategy, Spotfire, etc. to interact with Teiid. Developers can leverage the REST API or JDBC for custom built microservices and serverless workloads. In either case, for data consumers, Teiid appears as a standard PostgreSQL database accessed over its JDBC or ODBC protocols but offering additional abstractions and decoupling from the physical data sources.  is another popular open-source project started by Facebook. It is a distributed SQL query engine targeting big data use cases through its coordinator-worker architecture. The Coordinator is responsible for parsing statements, planning queries, managing workers, fetching results from the workers, and returning the final results to the client. The worker is responsible for executing tasks and processing data.  Some time ago, the founders split from PrestoDB and created a fork called (formerly PrestoSQL). Today, PrestoDB is part of The Linux Foundation, and Trino part of Trino Software Foundation. Both distributions of Presto are among the most active and powerful open-source data gateway projects in this space. To learn more about this technology, is a good book I found. CLOUD-HOSTED DATA GATEWAYS SERVICES With a move to the cloud infrastructure, the need for data gateways doesn’t go away but increases instead. Here are a few cloud-based data gateway services:  is ANSI SQL based interactive query service for analyzing data tightly integrated with Amazon S3. It is based on PrestoDB and supports additional data sources and federation capabilities too. Another similar service by Amazon is . It is focused around the same functionality, i.e. querying S3 objects using SQL. The main difference is that Redshift Spectrum requires a Redshift cluster, whereas Athena is a serverless offering that doesn’t require any servers.  is a similar service but from Google. These tools require minimal to no setup, they can access on-premise or cloud-hosted data and process huge datasets. But they couple you with a single cloud provider as they cannot be deployed on multiple clouds or on-premise. They are ideal for interactive querying rather than acting as hybrid data frontend for other services and tools to use. SECURE TUNNELING DATA-PROXIES With cloud-hosted data gateways comes the need for accessing on-premise data. Data has gravity and also might be affected by regulatory requirements preventing it from moving to the cloud. It may also be a conscious decision to keep the most valuable asset (your data) from cloud-coupling. All of these cases require cloud access to on-premise data. And cloud providers make it easy to reach your data. Azure’s  is such a proxy allowing access to on-premise data stores from Azure Service Bus. In the opposite scenario, accessing cloud-hosted data stores from on-premise clients can be challenging too. Google’s  provides secure access to Cloud SQL instances without having to whitelist IP addresses or configure SSL. Red Hat-sponsored open-source project  takes the more generic approach to address these challenges. Skupper solves Kubernetes multi-cluster communication challenges through a layer 7 virtual network that offers advanced routing and secure connectivity capabilities. Rather than embedding Skupper into the business service runtime, it runs as a standalone instance per Kubernetes namespace and acts as a shared sidecar capable of secure tunneling for data access or other general service-to-service communication. It is a generic secure-connectivity proxy applicable for many use cases in the hybrid cloud world. CONNECTION POOLS FOR SERVERLESS WORKLOADS Serverless takes software decomposition a step further from microservices. Rather than services splitting by bounded context, serverless is based on the function model where every operation is short-lived and performs a single operation. These granular software constructs are extremely scalable and flexible but come at a cost that previously wasn’t present. It turns out rapid scaling of functions is a challenge for connection-oriented data sources such as relational databases and message brokers. As a result cloud providers offer transparent data proxies as a service to manage connection pools effectively.  is such a service that sits between your application and your relational database to efficiently manage connections to the database and improve scalability. CONCLUSION Modern cloud-native architectures combined with the microservices principles enable the creation of highly scalable and independent applications. The large choice of data storage engines, cloud-hosted services, protocols, and data formats, gives the ultimate flexibility for delivering software at a fast pace. But all of that comes at a cost that becomes increasingly visible with the need for uniform real-time data access from emerging user groups with different needs. Keeping microservices data only for the microservice itself creates challenges that have no good technological and architectural answers yet. Data gateways, combined with cloud-native technologies offer features similar to API gateways but for the data layer that can help address these new challenges. The data gateways vary in specialization, but they tend to consolidate on providing uniform SQL-based access, enhanced security with data roles, caching, and abstraction over physical data stores. Data has gravity, requires granular access control, is hard to scale, and difficult to move on/off/between cloud-native infrastructures. Having a data gateway component as part of the cloud-native tooling arsenal, which is hybrid and works on multiple cloud providers, supports different use cases is becoming a necessity. This article was originally published on InfoQ .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/r9Na-7W7j-Y" height="1" width="1" alt=""/&gt;</content><dc:creator>Unknown</dc:creator><feedburner:origLink>http://www.ofbizian.com/2021/05/data-gateways-of-future.html</feedburner:origLink></entry><entry><title type="html">Webinar: Integrate systems in the age of Quarkus and Camel</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/g-Owy-ABX_4/webinar-integrate-systems-in-age-of.html" /><author><name>Claus Ibsen</name></author><id>http://feedproxy.google.com/~r/ApacheCamel/~3/BkZSRxVBBG4/webinar-integrate-systems-in-age-of.html</id><updated>2021-05-29T09:15:00Z</updated><content type="html">A few days ago I presented a webinar where he covered all the latest innovations with Apache Camel with focus on Camel Quarkus, Camel K, and Kamelets. This trio is a powerful combination that takes Camel to another level, which allows non developers and IT professionals, to manage and bind systems together without any Camel knowledge. Kamelets being the Apache Camel solution for an app store experience with integration software. The webinar is and the .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/g-Owy-ABX_4" height="1" width="1" alt=""/&gt;</content><dc:creator>Claus Ibsen</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/BkZSRxVBBG4/webinar-integrate-systems-in-age-of.html</feedburner:origLink></entry><entry><title>How to install Kubeflow 1.2 on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Lvgqj4tFZM4/how-install-kubeflow-12-red-hat-openshift" /><author><name>David Marcus</name></author><id>78521b1a-011c-4ff6-b07a-3c5e1142b49e</id><updated>2021-05-28T07:00:00Z</updated><published>2021-05-28T07:00:00Z</published><summary type="html">&lt;p&gt;As artificial intelligence (AI) adoption increases across industries, particularly through machine learning (ML), the job of integrating the often disparate tools, libraries, packages, and dependencies also increases in complexity. This makes development and operations (&lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt;) a daunting task that both organizations and open source communities are actively working on. To quote the authors of &lt;a href="https://web.kaust.edu.sa/Faculty/MarcoCanini/classes/CS290E/F19/papers/tech-debt.pdf"&gt;Hidden Technical Debt in Machine Learning Systems&lt;/a&gt;, "developing and deploying ML systems is relatively fast and cheap, but maintaining them over time is difficult and expensive."&lt;/p&gt; &lt;p&gt;If you are in the throes of tackling DevOps for &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;AI/ML&lt;/a&gt; (MLOps), two open source projects worth your attention are the upstream &lt;a href="https://www.kubeflow.org/"&gt;Kubeflow&lt;/a&gt; and the downstream &lt;a href="https://opendatahub.io/"&gt;Open Data Hub&lt;/a&gt; (ODH). The goal of these projects is to provide machine learning toolkits that handle the complex parts of orchestration that traditional software DevOps does not.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: For more about MLOps, see, &lt;a href="https://www.openshift.com/blog/dotscience-on-openshift"&gt;Dotscience on OpenShift: Enabling DevOps for MLOps&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As the name indicates, Kubeflow is based on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. In this article, we'll show it running on &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; and include an &lt;a href="https://developers.redhat.com/topics/service-mesh"&gt;Istio service mesh&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Objective&lt;/h2&gt; &lt;p&gt;Use this article as a startup procedure to install a default Kubeflow toolkit on an OpenShift Container Platform instance to explore the tools and capabilities. Figure 1 shows the Kubeflow dashboard running on OpenShift Container Platform, providing access to a suite of machine learning tools that span the system life cycle.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-ui.png?itok=G5FBZdI9" width="600" height="444" alt="Screenshot of the kubeflow central dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Kubeflow central dashboard. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Kubeflow central dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The latest release of Kubeflow at the time of this writing incorporates changes to the file structure for distribution-specific platforms, such as OpenShift. If you are interested in the details, you can read the source &lt;a href="https://github.com/kubeflow/manifests/pull/1739"&gt;pull request&lt;/a&gt; that explains the reason for the change.&lt;/p&gt; &lt;h3&gt;Overview of major steps&lt;/h3&gt; &lt;p&gt;The following list summarizes the steps needed to get Kubeflow running on OpenShift Container Platform:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Install the Open Data Hub Operator.&lt;/li&gt; &lt;li&gt;Create the Kubeflow project.&lt;/li&gt; &lt;li&gt;Install Kubeflow.&lt;/li&gt; &lt;li&gt;Monitor the installation.&lt;/li&gt; &lt;li&gt;Access the Kubeflow user interface (UI).&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;Requirements&lt;/h3&gt; &lt;p&gt;To use Kubeflow as shown in this article, please note the following requirements:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;You &lt;em&gt;must&lt;/em&gt; have an OpenShift Container Platform cluster 4.2+ installed with cluster admin privileges.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;should not&lt;/em&gt; have an &lt;a href="https://istio.io/latest/docs/ops/deployment/deployment-models/#multiple-meshes"&gt;existing Istio service mesh&lt;/a&gt;, because it will lead to name collisions.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;should not&lt;/em&gt;have an existing project named &lt;code&gt;istio-system&lt;/code&gt; as &lt;a href="https://www.kubeflow.org/docs/external-add-ons/istio/istio-in-kubeflow/"&gt;Kubeflow deploys Istio along with configurations&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;must not&lt;/em&gt; have remaining mutating webhooks or validating webhooks from prior tests.&lt;/li&gt; &lt;li&gt; &lt;p&gt;You &lt;em&gt;must not&lt;/em&gt; deploy Kubeflow in a project or namespace other than &lt;code&gt;kubeflow&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Running on an OpenShift cluster&lt;/h2&gt; &lt;p&gt;Here are some options for getting access to an OpenShift cluster to run through the procedure in this article. Getting a cluster running is beyond the scope of the tutorial, but the resources in this section offer a starting point.&lt;/p&gt; &lt;h3&gt;On your local machine cluster (recommended)&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt; is designed to run on a local computer to simplify setup and testing. The product emulates the cloud development environment with all of the tools needed to develop container-based applications.&lt;/p&gt; &lt;h3&gt;On a 60-minute temporary cluster (only for learning)&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.katacoda.com/openshift/courses/playgrounds/"&gt;Katacoda&lt;/a&gt; offers an OpenShift cluster as a playground that can be used to perform this installation, as long as you complete the task in an hour or less. It can be done.&lt;/p&gt; &lt;h3&gt;More options&lt;/h3&gt; &lt;p&gt;See the &lt;a href="https://www.openshift.com/try"&gt;OpenShift trial page&lt;/a&gt; for other options.&lt;/p&gt; &lt;h2&gt;Installing the Open Data Hub Operator&lt;/h2&gt; &lt;p&gt;Kubeflow should be installed on OpenShift using the Open Data Hub Operator from the &lt;a href="https://catalog.redhat.com/software/operators/explore"&gt;OpenShift Operators catalog&lt;/a&gt;. The upstream Kubeflow Operator from &lt;a href="http://operatorhub.io"&gt;OperatorHub.io&lt;/a&gt; will not run successfully on OpenShift because it is intended for a general-purpose Kubernetes cluster.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Operators&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;OperatorHub&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Search for "Open Data Hub."&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub Operator&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Continue&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Accept the default installation strategy, which uses the following settings: &lt;ul&gt;&lt;li&gt;Update Channel: beta&lt;/li&gt; &lt;li&gt;Installation mode: All namespaces on the cluster (default)&lt;/li&gt; &lt;li&gt;Installed Namespace: &lt;code&gt;openshift-operators&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Approval strategy: Automatic&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 2 illustrates the Open Data Hub Operator selection from the OpenShift OperatorHub.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-install.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-install.png?itok=piT5UOJ3" width="600" height="307" alt="Screenshot of Open Data Hub Operator install from the Red Hat OpenShift OperatorHub" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Open Data Hub Operator install. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Open Data Hub Operator installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating the Kubeflow project&lt;/h2&gt; &lt;p&gt;Kubeflow must be installed in a namespace called &lt;code&gt;kubeflow&lt;/code&gt;. A request for an alternative namespace is an &lt;a href="https://github.com/kubeflow/kubeflow/issues/5647"&gt;open issue&lt;/a&gt; at the time of this writing.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Home&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Projects&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create Project&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Set the following values: &lt;ul&gt;&lt;li&gt;Name: &lt;code&gt;kubeflow&lt;/code&gt; (cannot be altered)&lt;/li&gt; &lt;li&gt;Display Name: &lt;code&gt;kubeflow&lt;/code&gt; (unlike the previous name, you can choose another value here)&lt;/li&gt; &lt;li&gt;Description: Kubeflow ML toolkit (you can choose another value)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Change to the &lt;code&gt;kubeflow&lt;/code&gt; project.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Operators—&gt;Installed Operators&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Wait for the Operator to display "Succeeded" in the Status field.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 3 displays the expected result when the operator is completely installed.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-succeeded.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-succeeded.png?itok=Hovsw1gE" width="600" height="191" alt="Screenshot of Open Data Hub Operator with a succeeded status" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: ODH Operator successful installation. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: A succesful installation of the Open Data Hub Operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Installing Kubeflow&lt;/h2&gt; &lt;p&gt;By default, the Open Data Hub Operator includes a manifest that lets you try out different components for MLOps. Because the toolset used in this article is different from the one in the default manifest, you should paste in a different manifest.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Click the &lt;strong&gt;Open Data Hub Operator&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; link under &lt;strong&gt;Provided APIs&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create KfDef&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;YAML View&lt;/strong&gt; radio button.&lt;/li&gt; &lt;li&gt;Delete all the YAML code.&lt;/li&gt; &lt;li&gt;Copy and paste in all the YAML code from &lt;a href="https://raw.githubusercontent.com/kubeflow/manifests/master/distributions/kfdef/kfctl_openshift.v1.2.0.yaml"&gt;kfctl_openshift.v1.2.0.yaml&lt;/a&gt;. &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For reference, the HTML version can be found on &lt;a href="https://github.com/kubeflow/manifests/tree/master/distributions/kfdef"&gt;Kubeflow GitHub manifests&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create&lt;/strong&gt; button.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 4 shows the Provided APIs selection.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-api.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-api.png?itok=V9y8Mcio" width="600" height="190" alt="Screenshot of the provided API for selection to create a KfDef and edit YAML" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Open Data Hub Provide API. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Open Data Hub Provided APIs.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Figure 5 shows the YAML code you will replace.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kfctl-yaml.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kfctl-yaml.png?itok=nEXuGo9_" width="600" height="444" alt="Screenshot of the YAML View to replace existing YAML with provided YAML for Kubeflow" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: ODH Provided API KfDef YAML View. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Open Data Hub Provided API KfDef YAML View.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Monitoring the installation&lt;/h2&gt; &lt;p&gt;In the background, the Open Data Hub Operator performs the commands a system administrator would execute on the command line to install Kubeflow, such as &lt;code&gt;kfctl build -f...&lt;/code&gt; and &lt;code&gt;kfctl apply -f...&lt;/code&gt; The web console doesn't show when the installation is complete, so this section shows a few ways to monitor the installation. If all the pods are running without errors, the installation is complete.&lt;/p&gt; &lt;h3&gt;Monitoring from the administrator perspective&lt;/h3&gt; &lt;p&gt;Streaming events are a great way to get a sense of what major activity is occurring after an action such as a deployment. To view the events:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Home&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Section the project: either &lt;code&gt;kubeflow&lt;/code&gt; to see just events for Kubeflow, or "All projects" to see the multiple projects being updated during installation.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Events&lt;/strong&gt; to monitor the deployment events stream.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 6 shows the events streaming during an installation in the &lt;code&gt;kubeflow&lt;/code&gt; project.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/events.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/events.png?itok=oi84DHiL" width="600" height="289" alt="Screenshot of the event stream during a new kubeflow installation" title="Project kubeflow event stream" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Event stream during installation &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Event stream during installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Workload status and alerts are a quick way to understand how progress is going. To view the workloads:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Projects&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;code&gt;kubeflow&lt;/code&gt; project link.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Workloads&lt;/strong&gt; menu item in the body of the screen to review pods.&lt;/li&gt; &lt;li&gt;Investigate workloads that don't self-correct (give them time to auto-correct).&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 7 shows workloads from the project overview page. Workloads in the project are also viewable from the vertical menu.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/overview.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/overview.png?itok=OE9glwyg" width="600" height="444" alt="Screenshot of the workloads from the project overview page" title="Kubeflow Workload Overview" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Kubeflow project Workloads overview &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Overview of the Kubeflow project workloads.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A project called &lt;code&gt;cert-manager&lt;/code&gt; gets created during installation. Its events and pods provide good insight. To view these events or pods:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: cert-manager&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Events&lt;/strong&gt; to review events. Under &lt;strong&gt;Workloads&lt;/strong&gt;, click &lt;strong&gt;Pods&lt;/strong&gt; to review pods.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 8 shows the pods for &lt;code&gt;cert-manager&lt;/code&gt;.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/cert-manager.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/cert-manager.png?itok=8DCGiju1" width="600" height="213" alt="Screenshot of the pods in the cert-manager project that gets created" title="Cert-manager project pods" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Project cert-manager pods status &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 8: Status of pods in the cert-manager pods status.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Another important project, &lt;code&gt;istio-system&lt;/code&gt;, is created during installation. This project hosts the Istio service mesh that handles all the networking between the services. To view the project:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Events&lt;/strong&gt; to review events. Under &lt;strong&gt;Workloads&lt;/strong&gt;, click &lt;strong&gt;Pods&lt;/strong&gt; to review pods. Under &lt;strong&gt;Networking&lt;/strong&gt;, click &lt;strong&gt;Routes&lt;/strong&gt; to access the URL to the Kubeflow central dashboard.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 9 shows the routes in the project.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/istio-route.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/istio-route.png?itok=PFfmkJTw" width="600" height="323" alt="Screenshot of the istio ingress gateway route to access kubeflow interface" title="Project istio-system routes" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Istio-system route for istio-ingressgateway &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: istio-system route for the istio-ingress gateway.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Monitoring from the developer perspective&lt;/h3&gt; &lt;p&gt;In addition to the administrator perspective, a developer perspective abstracts infrastructure features out of view to leave an uncluttered developer experience. To see this perspective:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to the &lt;strong&gt;developer&lt;/strong&gt; perspective.&lt;/li&gt; &lt;li&gt;Select &lt;strong&gt;Project: kubeflow&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Topology&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 10 shows the results.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kfctl-topology.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kfctl-topology.png?itok=fLwITOUL" width="600" height="426" alt="Screenshot of the app topology created in the kubeflow project" title="Developer Perspective Topology View" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: Developer Perspective kubeflow project topology &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 10: Kubeflow project topology in the developer perspective.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If there are no errors across the projects and the Kubeflow UI launches, the installation has succeeded.&lt;/p&gt; &lt;h2&gt;Accessing the Kubeflow UI&lt;/h2&gt; &lt;p&gt;This section offers two ways to access the Kubeflow central dashboard from the web console. For reference, a command-line query would look like:&lt;/p&gt; &lt;pre&gt; # oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}/' &lt;/pre&gt; &lt;h3&gt;Going to the dashboard from the administrator perspective&lt;/h3&gt; &lt;p&gt;From the administrator perspective, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Networking&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Routes&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the location URL &lt;code&gt;http://istio-ingressgateway...&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 11 shows how to find the location URL.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-dashboard.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-dashboard.png?itok=xGlofgx1" width="600" height="224" alt="Screenshot of the kubeflow dashboard route in the istio-system project" title="Route to Kubeflow Dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: Route to Kubeflow Dashboard in the istio-system project &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 11: Route to the Kubeflow dashboard in the istio-system project.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Going to the dashboard from the developer perspective&lt;/h3&gt; &lt;p&gt;From the developer perspective, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Topology&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Search for "istio-ingressgateway."&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open URL&lt;/strong&gt; arrow icon, or click the &lt;code&gt;istio-ingressgateway&lt;/code&gt; pod and the URL under &lt;strong&gt;Resources—&gt;Routes&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 12 shows the location of the URL.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-route.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-route.png?itok=8JfpGtYM" width="600" height="416" alt="Screenshot of the app topology of the istio-system project to access Kubeflow dashboard" title="Kubeflow Topology Route" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 11: Developer Perspective route to Kubeflow from istio-system project &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 12: Developer perspective route to Kubeflow from istio-system project.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Viewing the Kubeflow central dashboard&lt;/h3&gt; &lt;p&gt;Once you complete the registration process and create a namespace, you will see a dashboard like the one in Figure 13.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-ui.png?itok=G5FBZdI9" width="600" height="444" alt="Screenshot of the kubeflow central dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Kubeflow central dashboard. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 13: The Kubeflow central dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Uninstalling Kubeflow&lt;/h2&gt; &lt;p&gt;No proper installation procedure is truly complete without an uninstallation procedure.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project kubeflow&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; Operator.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; link under &lt;strong&gt;Provided APIs&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Kebab&lt;/strong&gt; button (the one with three vertical dots) for your &lt;code&gt;kubeflow&lt;/code&gt; instance.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Delete KfDef&lt;/strong&gt; to begin the delete process for your &lt;code&gt;kubeflow&lt;/code&gt; instance.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;The procedure in this article illustrates a best practice you can follow to install Kubeflow on Red Hat OpenShift using the Open Data Hub Operator. The manifest file used provides an example toolkit from the Kubeflow project that you can fork, modify, and update to fit your production MLOps needs. Furthermore, the &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Operator framework&lt;/a&gt; simplifies installation, operations, and maintenance as the community &lt;a href="https://opendatahub.io/docs/roadmap/future.html"&gt;continues to publish enhancements&lt;/a&gt; to both the operator and machine learning tooling in conjunction with the overall &lt;a href="https://www.openshift.com/learn/topics/ai-ml"&gt;benefits of AI/ML on Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/28/how-install-kubeflow-12-red-hat-openshift" title="How to install Kubeflow 1.2 on Red Hat OpenShift"&gt;How to install Kubeflow 1.2 on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Lvgqj4tFZM4" height="1" width="1" alt=""/&gt;</summary><dc:creator>David Marcus</dc:creator><dc:date>2021-05-28T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/28/how-install-kubeflow-12-red-hat-openshift</feedburner:origLink></entry><entry><title>How to update to newer Red Hat OpenShift 4 releases</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Q17YrPMCT1I/how-update-newer-red-hat-openshift-4-releases" /><author><name>Fernando Lozano</name></author><id>9ecbbc93-71a1-49f1-b629-956f00987bbb</id><updated>2021-05-27T07:00:00Z</updated><published>2021-05-27T07:00:00Z</published><summary type="html">&lt;p&gt;This article demonstrates two common scenarios for updating &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift 4&lt;/a&gt;: to a newer z-stream release and to a newer minor release. I include plenty of screenshots of actual updates from 4.5.4 to 4.5.17 and then to 4.6.4, so you know what to expect when you make these updates yourself.&lt;/p&gt; &lt;p&gt;OpenShift 4 makes the update process easy and provides a number of safety features to minimize the risk of a failed outcome. Still, updating OpenShift clusters can be scary the first time. This article shows how two perform typical update scenarios, step-by-step:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Updating between two z-stream releases, from 4.y.z to 4.y.z+d. Note that you can skip z-stream releases during an update.&lt;/li&gt; &lt;li&gt;Updating between two minor releases, from 4.y to 4.y+1. Note that you cannot skip a minor release during an update.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;To use or not to use the web console&lt;/h2&gt; &lt;p&gt;The update process, including web console pages and quirks, is mostly the same for earlier minor releases, for example a z-stream update of OpenShift 4.4. OpenShift 4.6 includes significant improvements to its web console that solve most if not all of the gotchas that I demonstrate in this article.&lt;/p&gt; &lt;p&gt;You can perform the entire cluster update process from the command-line interface (CLI) and automate it using Ansible playbooks, shell scripts, or whatever you like. If you need instructions about how to perform a cluster update using the CLI, please refer to the &lt;a href="https://docs.openshift.com/container-platform/4.5/updating/updating-cluster-cli.html"&gt;Red Hat OpenShift Container Platform product documentation&lt;/a&gt; and this &lt;a href="https://access.redhat.com/solutions/4606811"&gt;article from the OpenShift knowledgebase&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you have a test cluster that you were considering updating for some time and did not, for fear of the outcome, you can use the cluster now to follow the instructions from this article.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Do not try to update a &lt;a href="https://developers.redhat.com/products/codeready-containers"&gt;Red Hat CodeReady Containers&lt;/a&gt; (CRC) single-node cluster. CodeReady Containers disables some of the cluster operators required for a successful update in order to reduce its hardware requirements, and the OpenShift update process was not designed to work with a single supervisor node, anyway. Later releases of &lt;a href="https://developers.redhat.com/courses/openshift/getting-started"&gt;OpenShift Container Platform&lt;/a&gt; will support single-node OpenShift (SNO) clusters, which follow a different design and installation process from CodeReady Containers. SNO clusters will support updates when they become generally available.&lt;/p&gt; &lt;p&gt;Because the set of available updates and paths changes from time to time, you might not be able to follow the instructions in this article exactly as written. You might start from a different release, target a different final release, and have to pass through different intermediate releases. I hope to provide you with sufficient information to extrapolate to your specific scenario.&lt;/p&gt; &lt;h2&gt;What is the current version of my OpenShift cluster?&lt;/h2&gt; &lt;p&gt;Open your OpenShift web console, log in with cluster administrator rights, and choose &lt;strong&gt;Administration—&gt;Cluster Settings&lt;/strong&gt;. You should see a page that displays your cluster’s current update channel and OpenShift release. Mine is using the somewhat old 4.5.4 release, as shown in Figure 1. I have not updated my test cluster since it was first installed a while ago.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-1-version-4.5.4-2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-1-version-4.5.4-2.png?itok=SzbKg03Q" width="600" height="234" title="blog-1-version-4.5.4" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Viewing the current cluster settings.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If I click on the pen icon beside my current update channel, which is stable-4.5, the web console allows me to choose only from other channels of the same OpenShift release (see Figure 2). That means that my current release cannot be immediately updated to the next minor release—at least not using the web console.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-2-no-4.5-channel.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-2-no-4.5-channel.png?itok=o8Dt20bt" width="600" height="338" title="blog-2-no-4.5-channel" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Available channels for updates.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For now, do not change the update channel.&lt;/p&gt; &lt;h2&gt;Why don't I see the channel for the next minor OpenShift release?&lt;/h2&gt; &lt;p&gt;It might be possible to update directly to an OpenShift 4.6.x release from the CLI, but up to OpenShift 4.5, the web console comes with a hardcoded list of candidate update channels. The initial z-stream releases hard-code just their own update channels. Later z-stream releases add channels of the next minor release.&lt;/p&gt; &lt;p&gt;OpenShift 4.6 changes the offerings so that the list of available update channels becomes dynamic and shows channels from new releases as they become available. That means that an early 4.6.z release might become updatable to 4.7 without passing through intermediate 4.6.z releases, using the web console.&lt;/p&gt; &lt;p&gt;As I am still on 4.5 and I wish to follow the easy user interface (UI) provided by the web console, I have to first update to a newer 4.5.z release. Shame on me for leaving my cluster for so long without bug fixes and security updates! That is about to be corrected.&lt;/p&gt; &lt;p&gt;If I were in a hurry to update to OpenShift 4.6, or maybe to a very recent 4.5.x release, for example to get the fix for a critical bug that is affecting my production users, I might have to switch to a fast channel. Updates to OpenShift 4 are made available first in the fast channel. Only after a number of customers successfully run a given release without major incidents is an update added to the stable channel.&lt;/p&gt; &lt;p&gt;OpenShift update channels and upgrade paths contain many more nuances than I explain in this article. For deeper information about how Red Hat manages OpenShift update channels and releases, refer to &lt;a href="https://www.openshift.com/blog/the-ultimate-guide-to-openshift-release-and-upgrade-process-for-cluster-administrators"&gt;The Ultimate Guide to OpenShift Release and Upgrade Process for Cluster Administrators&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Updating to a newer z-stream release&lt;/h2&gt; &lt;p&gt;My test cluster is running release 4.5.4 and using the stable-4.5 channel. If I click &lt;strong&gt;Update now&lt;/strong&gt;, the web console presents me a list of releases that I can update to, with the more recent releases shown first (see Figure 3).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-3-update-to-4.5.17.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-3-update-to-4.5.17.png?itok=XFQi75B7" width="600" height="522" title="blog-3-update-to-4.5.17" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Selecting a version of OpenShift to update to after "Update now".&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Remember that the screenshot represents a point in time, in this case November 2020. You might see more (or fewer!) releases when you view them yourself.&lt;/p&gt; &lt;p&gt;The list might not include the latest release from your current channel. It includes only the ones with a direct update path from your current release. A few update cycles might take place before you get to the release you want or run out of update paths.&lt;/p&gt; &lt;p&gt;I select the 4.5.17 release, which is the latest as I write this article, and click &lt;strong&gt;Update&lt;/strong&gt;. After a few moments, the web console starts displaying the status of my update, as shown in Figure 4.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-4-working-to-4.5.17.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-4-working-to-4.5.17.png?itok=p7pJZDiv" width="600" height="225" title="blog-4-working-to-4.5.17" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: The update status.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The time to update depends on a number of factors, such as your internet bandwidth, size of the &lt;a href="https://developers.redhat.com/products/rhel "&gt;Red Hat Enterprise Linux&lt;/a&gt; CoreOS images and cluster operator images, number of nodes on your cluster, number of applications, their disruption budgets, and many other factors. My compact test cluster (only three nodes) took about 40 minutes.&lt;/p&gt; &lt;h2&gt;Web console quirks while updating&lt;/h2&gt; &lt;p&gt;During updates I saw a couple of times that the percent-complete indicator moved backward, for example from 70% to 25%. Don’t panic if that happens to you. I also saw a few temporary failures that disappeared without action from me, which I will explain later in this article. The upstream &lt;a href="https://github.com/openshift/cluster-version-operator/blob/master/docs/dev/upgrades.md#why-does-the-openshift-4-upgrade-process-restart-in-the-middle"&gt;Cluster Version Operator (CVO) documentation&lt;/a&gt; explains why that happens; it is by design.&lt;/p&gt; &lt;p&gt;At some time during the update, your web console session might expire because the update process restarts web console pods to use a new container image. You might even get a “server error” from the OpenShift router. If that happens, refresh your web browser, log in again (if needed), and navigate back to &lt;strong&gt;Administration—&gt;Cluster Settings&lt;/strong&gt; to continue monitoring the progress of your cluster update.&lt;/p&gt; &lt;p&gt;The stated OpenShift goal of 100% availability during updates does not mean that all HTTP requests to the web console and applications are successful. During an update, nodes are rebooted, pods are recreated, containers are stopped, and new containers are started. Load balancers might not react instantly and might send an occasional request to a container or a node that is not available. The next HTTP request should work.&lt;/p&gt; &lt;h2&gt;Is my OpenShift update done?&lt;/h2&gt; &lt;p&gt;When the update finishes, the web console shows your new current version and might also show that more updates are available (see Figure 5).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-5-version-4.5.17.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-5-version-4.5.17.png?itok=xb4Xv_FG" width="600" height="234" title="blog-5-version-4.5.17" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: The Cluster Settings screen after a successful update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In my example, it looks like I still am unable to get to any 4.6 channel, but I see a single 4.5 release I could update to (see Figure 6).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-6-update-to-4.5.18.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-6-update-to-4.5.18.png?itok=dOdAdvfq" width="600" height="322" title="blog-6-update-to-4.5.18" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Checking for newer versions on the Update Cluster screen after an update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So, I would repeat the process I've shown in this article to update to 4.5.18 and so on, in the hope of being able eventually to update to OpenShift 4.6. (I know that I do not need further updates, and I will explain later how I know that.)&lt;/p&gt; &lt;p&gt;Before you update again to the next z-stream release, refresh your browser tab. Your web browser might be displaying stale data from your previous cluster version. OpenShift 4.6 solves that particular issue and requires no browser refresh.&lt;/p&gt; &lt;h2&gt;Is my OpenShift update failing?&lt;/h2&gt; &lt;p&gt;I did a few cluster updates without any issues, from the same test environment. But one of my attempts displayed a scary, red exclamation icon and a “Failing” status, shown in Figure 7.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-7-failing.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-7-failing.png?itok=UHQ-cyEv" width="600" height="232" title="blog-7-failing" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Status of "Failing".&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Calm down and notice that the status is “fail-&lt;em&gt;ing&lt;/em&gt;,” not “fail-&lt;em&gt;ed&lt;/em&gt;." The update process is still running. &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; clusters, applications, and operators can self-heal in a large number of scenarios. Sometimes the "Failing" message is caused by &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1884334"&gt;too short a timeout&lt;/a&gt; in the CVO. If that is the case, the message will fix itself with no action from you. And with no damage to your cluster and applications.&lt;/p&gt; &lt;p&gt;Do not panic, but give some time for OpenShift to heal itself. Be patient before you start collecting troubleshooting information and opening customer support tickets.&lt;/p&gt; &lt;h2&gt;Pending cluster operators&lt;/h2&gt; &lt;p&gt;If you click &lt;strong&gt;View details&lt;/strong&gt;, as shown in Figure 7, the web console shows you detailed information about the status of each cluster operator: Which ones have already finished updating and which ones are still performing their updates. Figure 8 shows that the &lt;code&gt;openshift-apiserver&lt;/code&gt; operator became degraded.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-8-degraded.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-8-degraded.png?itok=G3IkqUQE" width="600" height="337" title="blog-8-degraded" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 8: The cluster operators screen with a progress message showing a potential problem.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;I hope that the message “Cluster update &lt;em&gt;in progress&lt;/em&gt;," together with the less-alarming, blue information icon gives you some peace of mind: OpenShift is still performing the update; it has not failed at all.&lt;/p&gt; &lt;p&gt;Operators can become degraded for a while during updates and then recover by themselves. It is expected that, with each new OpenShift release, cluster operators become better at reporting their status and report fewer temporary failures.&lt;/p&gt; &lt;p&gt;Scrolling down, I can see that one of my API server pods is not running (see Figure 9). I know that this might happen when you update a Kubernetes deployment, so I decide to just give it some time to settle down.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-9-api-server.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-9-api-server.png?itok=f6zBNKwn" width="600" height="252" title="blog-9-api-server" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: A degraded pod on the Cluster Operators screen.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If I suspected that something was wrong, maybe because I saw other operators with errors, I would check the operator logs and cluster events to find a hint of a real unrecoverable error.&lt;/p&gt; &lt;p&gt;After a few minutes, the “Failing” state switches to “Update available” and the desired cluster version, 4.5.17, becomes the current version. My update finishes successfully, as shown in Figure 10.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-10-update-avail.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-10-update-avail.png?itok=5jpzTpRz" width="600" height="234" title="blog-10-update-avail" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 10: The Cluster Settings screen showing the current version after an update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;That “Failing” state could also switch to a new percent-complete message, as if the update process is just progressing and no failure ever happened. You might even see the installation go into a “Failing” state and then back to “Working towards” states a few times.&lt;/p&gt; &lt;p&gt;In the end, the changes you notice depend on how much attention you pay to the web console while your cluster is updating. Because I know the update is supposed to take time, I usually perform other tasks instead of staring at the OpenShift web console’s &lt;strong&gt;Cluster Settings&lt;/strong&gt; page. If something really bad happens during my update, I expect OpenShift cluster monitoring to alert me.&lt;/p&gt; &lt;h2&gt;Updating to a newer minor release&lt;/h2&gt; &lt;p&gt;You might not be able to update from your current 4.y.z release to any 4.y+1 release, using the web console, prior to OpenShift 4.6. It might be necessary to update to a newer 4.y.z+d before the web console shows a channel for the next minor release. You might even have to perform multiple z-stream updates.&lt;/p&gt; &lt;p&gt;In my sample scenario, I had to update from OpenShift 4.5.3 to 4.5.17 to get the possibility of switching to the stable-4.6 channel. With my cluster updated to 4.5.17, and also after a web browser page refresh, the web console offered me the choice of a stable channel for the next minor release of OpenShift (see Figure 11).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-11-update-4.6.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-11-update-4.6.png?itok=QkLUUgC6" width="600" height="452" title="blog-11-update-4.6" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 11: The Update Channel screen showing 4.6 releases.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;To update to the next minor release, click on &lt;strong&gt;stable-4.6&lt;/strong&gt; to switch channels, click &lt;strong&gt;Update now&lt;/strong&gt;, and then select any of the available 4.6.z releases as the new OpenShift release for your cluster. The update process from now on is the same as a z-stream update.&lt;/p&gt; &lt;h2&gt;Is it too soon to update?&lt;/h2&gt; &lt;p&gt;The first time I tried to update from OpenShift 4.5 to 4.6, by switching from the stable-4.5 to the stable-4.6 channel, I got the disappointing “Version not found” status in Figure 12. It didn't make any difference if I didn't stop at 4.5.17, but continued to update to 4.5.18 or later.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-12-update-not-found.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-12-update-not-found.png?itok=28XM7I8T" width="600" height="204" title="blog-12-update-not-found" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 12: The update was not found.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The message means that the stable-4.6 channel does not include my current version. At that time, the stable-4.6 channel did not include 4.5.18 (nor 4.5.17, for that matter).&lt;/p&gt; &lt;p&gt;Figure 13 shows a fully updated OpenShift 4.5 cluster, according to its current release update channel (stable-4.5), so you can compare it to the previous figure. The “Up to date” status means that the channel lists my current release only as an update path destination, and not as a source of any path. So there are no updates available currently, but an update might become available in the future.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-13-up-to-date.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-13-up-to-date.png?itok=xdroVXi4" width="600" height="252" title="blog-13-up-to-date" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 13: The Cluster Settings screen when the OpenShift version is up to date.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If you find yourself in a similar scenario (that is, you switch to the stable channel of the next minor release, and find that no updates are available), Red Hat recommends that you switch back to a channel that lists your current release so you do not miss bug fixes and security updates. In my example, I would switch back to stable-4.5. Indeed, a few days later that channel got 4.5.19 and 4.5.20. But none of these releases are published to stable-4.6 as I write.&lt;/p&gt; &lt;p&gt;Because I tried checking only a few days after the first generally available (GA) release of OpenShift 4.6, all update paths were likely waiting for proof of stability from clusters using the fast channel.&lt;/p&gt; &lt;p&gt;If you find yourself in the same situation, you have two choices: Either check the stable-4.6 channel again from time to time, until you see a 4.6.z release update on the stable-4.6 channel, and revert back to the stable-4.5 after each check; or switch to the fast channel in the hope that there is an update path there.&lt;/p&gt; &lt;h2&gt;Using the fast channel&lt;/h2&gt; &lt;p&gt;In my case, after I switch to the fast-4.6 channel, I see that there are indeed updates available (see Figure 14).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-13-up-to-date.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-13-up-to-date.png?itok=xdroVXi4" width="600" height="252" title="blog-13-up-to-date" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 14: The Cluster Settings screen for the fast-4.6 channel shows updates available.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;And I could pick two releases to update from 4.5.18: 4.6.3 (not shown in Figure 15) and 4.6.4.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-15-update-to-4.6.4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-15-update-to-4.6.4.png?itok=UaBYqOvp" width="600" height="324" title="blog-15-update-to-4.6.4" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 15: Version 4.6.4 selected for update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Figure 16 is proof that my test cluster finished its update to 4.6.4 using the fast channel. Notice the change in the look and feel of the web console. After OpenShift 4.7 is released, I will write a new article with new screenshots.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-16-version-4.6.4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-16-version-4.6.4.png?itok=o0wa5AO_" width="600" height="270" title="blog-16-version-4.6.4" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 16: The Cluster Settings screen after version 4.6.4 is selected for update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Do not be afraid of updating your cluster using a fast channel if you need an update right now. Red Hat fully supports using all releases from the fast channel in production environments. Make the decision to switch, or wait based on your needs for these updates and the potential impacts of waiting a little longer to update.&lt;/p&gt; &lt;h2&gt;How to find which updates are available?&lt;/h2&gt; &lt;p&gt;You might not consider it intuitive that the OpenShift web console allows you to switch to a channel when no updates are available. It makes sense once you consider that you select a channel to signal your intent of getting updates from that channel. If you pick a very new channel, as I did, there might be very few update paths. Then it is no surprise that a given release is not in any of them.&lt;/p&gt; &lt;p&gt;Having to switch channels and wait for intermediate cluster updates before you find whether you can update to the desired OpenShift release could be frustrating. Fortunately, there are multiple ways of checking for available updates. OpenShift 4.6 allows you to find them before performing an update. But because I am still on 4.5, I have to search outside of the web console.&lt;/p&gt; &lt;p&gt;One way is to use the &lt;a href="https://ctron.github.io/openshift-update-graph/#stable-4.6"&gt;OpenShift Update Graph&lt;/a&gt;. It shows a nice-looking, though sometimes confusing, graph of all update paths available for the selected channel. For example, I got the results shown in Figure 17 in mid-November 2020.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-17-graph-stable.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-17-graph-stable.png?itok=_WWAX_iS" width="222" height="226" title="blog-17-graph-stable" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 17: Limited versions were available in the OpenShift Update Graph.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;At the time I generated Figure 17, there was no update path from any 4.5.z release to 4.6 in the stable channel. When I instead selected the fast-4.6 channel, I got the much richer graph in Figure 18.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-18-graph-fast.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-18-graph-fast.png?itok=cYwNojjy" width="600" height="490" title="blog-18-graph-fast" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 18: Numerous versions shown in the OpenShift Update Graph.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;To help you visualize the state of that graph at the time I captured the screenshots for this article, I colored all 4.5.z releases with arrows getting to any 4.6.z release and zoomed in so that this part of the graph is easier to read (see Figure 19).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-19-zoom-fast.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-19-zoom-fast.png?itok=0z6VnSce" width="326" height="317" title="blog-19-zoom-fast" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 19: Focusing on 4.5.z versions in the OpenShift Update Graph.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Figure 19 makes it easier to see that I could update from 4.5.16, 4.5.17, 4.5.18, and 4.5.19 to an OpenShift 4.6 release using the fast-4.6 channel.&lt;/p&gt; &lt;h2&gt;Finding available updates from the shell&lt;/h2&gt; &lt;p&gt;Another way to list update paths from an OpenShift 4 update channel comes from &lt;a href="https://access.redhat.com/solutions/4583231"&gt;this article&lt;/a&gt;. The following example lists all updates available for 4.5.4 from the stable-4.5 channel. The last command includes a very long &lt;code&gt;jq&lt;/code&gt; filter. Make sure the entire filter is a single shell argument. Notice the single quotes around it.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ export CURRENT_VERSION=4.5.4 $ export CHANNEL_NAME=stable-4.5 $ curl -sH 'Accept:application/json' "https://api.openshift.com/api/upgrades_info/v1/graph?channel=${CHANNEL_NAME}" | jq -r --arg CURRENT_VERSION "${CURRENT_VERSION}" '. as $graph | $graph.nodes | map(.version=='\"$CURRENT_VERSION\"') | index(true) as $orig | $graph.edges | map(select(.[0] == $orig)[1]) | map($graph.nodes[.].version) | sort_by(.)' [ "4.5.11", "4.5.13", "4.5.14", "4.5.15", "4.5.16", "4.5.17", "4.5.5", "4.5.6", "4.5.7", "4.5.8", "4.5.9", ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;All those pipe signs (|) belong to the &lt;code&gt;jq&lt;/code&gt; filter. They are part of the fifth argument of the &lt;code&gt;jq&lt;/code&gt; command. Do not mistake them for shell pipes! Also note that the &lt;code&gt;jq&lt;/code&gt; filter sorts its output in a somewhat misleading way. It uses string ordering, not semantic version ordering. Notice that the most recent version, which was 4.5.17, appears in the middle of the output.&lt;/p&gt; &lt;p&gt;An alternative to writing that long &lt;code&gt;jq&lt;/code&gt; filter is using the &lt;a href="https://github.com/openshift/cincinnati/blob/master/hack/available-updates.sh"&gt;available-updates.sh&lt;/a&gt; script from the Cincinnati developers. The CVO uses the Cincinnati protocol to describe update channels.&lt;/p&gt; &lt;p&gt;Download the &lt;code&gt;available-updates.sh&lt;/code&gt; script and make it executable. Then set the &lt;code&gt;CHANNEL&lt;/code&gt; environment variable and pass the starting version as an argument. The following example lists what would be my options after I update to 4.5.17, using the fast-4.6 channel:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ export CHANNEL=fast-4.6 $ ./available-updates.sh 4.5.17 4.5.18 quay.io/openshift-release-dev/ocp-release@sha256:72e3..f366 https://access.redhat.com/errata/RHBA-2020:4425 4.6.4 quay.io/openshift-release-dev/ocp-release@sha256:6681..86fc https://access.redhat.com/errata/RHBA-2020:4987&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If I try the stable-4.6 channel I get an empty list, that is, &lt;code&gt;[]&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;By viewing the output of these commands, I was able to plan for two updates starting from 4.5.4: first to 4.4.17 and then to 4.6.4 using the fast channel.&lt;/p&gt; &lt;p&gt;As you might guess, many developers created their own visualization tools and scripts to report OpenShift cluster updates. An example is &lt;a data-pjax="#js-repo-pjax-container" href="https://github.com/pamoedom/ocp4upc"&gt;ocp4upc&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;OpenShift 4 updates do not have to be scary. The web console makes updates easy to do, and the underlying infrastructure provided by the CVO makes the process very reliable and dependable.&lt;/p&gt; &lt;p&gt;There are a few quirks in the way the web console handles updates up to OpenShift 4.5. Fortunately, OpenShift 4.6 solves most of them.&lt;/p&gt; &lt;p&gt;The OpenShift update process is very consistent with Kubernetes’s design patterns: You declare the desired state of your cluster and let Kubernetes converge the current state to the desired state.&lt;/p&gt; &lt;p&gt;For more information about how the OpenShift CVO and cluster operators handle cluster updates, please see the video &lt;a href="https://www.openshift.com/blog/red-hat-openshift-cluster-upgrades-and-application-operator-updates"&gt;Red Hat OpenShift: Cluster Upgrades and Application Operator Updates&lt;/a&gt; and also the excellent post from the official OpenShift blog: &lt;a href="https://www.openshift.com/blog/the-ultimate-guide-to-openshift-release-and-upgrade-process-for-cluster-administrators"&gt;The Ultimate Guide to OpenShift Release and Upgrade Process for Cluster Administrators&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;Thanks to Eric Rich and Mike Allmen for their reviews of drafts of this article. Also thanks to W. Trevor King and Scott Dodson for their many valuable comments improving the technical information in this article. If you find any errors and inaccuracies in this article, they are mine only despite their best efforts.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/27/how-update-newer-red-hat-openshift-4-releases" title="How to update to newer Red Hat OpenShift 4 releases"&gt;How to update to newer Red Hat OpenShift 4 releases&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Q17YrPMCT1I" height="1" width="1" alt=""/&gt;</summary><dc:creator>Fernando Lozano</dc:creator><dc:date>2021-05-27T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/27/how-update-newer-red-hat-openshift-4-releases</feedburner:origLink></entry><entry><title type="html">Writing fast constraints with OptaPlanner: the secret recipe</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/eaW922tbOWw/writing-fast-constraints-with-optaplanner-the-secret-recipe.html" /><author><name>triceo</name></author><id>https://blog.kie.org/2021/05/writing-fast-constraints-with-optaplanner-the-secret-recipe.html</id><updated>2021-05-27T00:00:00Z</updated><content type="html">Do you want OptaPlanner to run faster? Do you want to increase your score calculation speed, reaching great solutions sooner? Let me show you how to optimize your constraints for performance and scalability. Turns out you only need to remember one advice: DO LESS The key to well-performing constraints is limiting the amount of data that flows through your Constraint Streams, which starts with . Consider a school timetabling problem, where a teacher must not have two overlapping lessons. This is how the lesson could look in Java: @PlanningEntity class Lesson { ... Teacher getTeacher() { ... } boolean overlaps(Lesson anotherLesson) { ... } boolean isCancelled() { ... } ... } The simplest possible Constraint Stream we could write to penalize all overlapping lessons would then look like: constraintFactory.from(Lesson.class) .join(Lesson.class) .filter((leftLesson, rightLesson) -&gt; !leftLesson.isCancelled() &amp;amp;&amp; !rightLesson.isCancelled() &amp;amp;&amp; leftLesson.getTeacher() .equals(rightLesson.getTeacher()) &amp;amp;&amp; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) What this Constraint Stream does is: 1. It creates all possible pairs of Lessons from the planning solution. 2. Then it all the lessons that are cancelled, where the teachers do not match, or which do not overlap. 3. It all the remaining lesson pairs. Do you see the problem here? The join creates a cross product between lessons, producing a match (also called a tuple) for every possible combination of two lessons, even though we know that many of these matches will not be penalized. This shows the problem in numbers: In order to process a thousand lessons, our constraint first creates a cross product of 1 million pairs, only to throw away pretty much all of them before penalizing! If we can reduce the size of the cross product by half, only half of the time will be spent processing it. This is where the original advice comes into play: do less, by avoiding unrestricted cross product. Here’s how. Table 1. Fast growth of cross product Number of lessons Number of possible pairs 10 100 100 10 000 1 000 1 000 000 FILTER BEFORE JOINING As you can see from the first example, cancelled lessons are eventually filtered out after the join. Let’s see if we can remove them from the cross product instead. For the first lesson in the join (also called “left”), this is straightforward; we simply bring the cancellation check before the join like so: constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()) .join(Lesson.class) .filter((leftLesson, rightLesson) -&gt; !rightLesson.isCancelled() &amp;amp;&amp; leftLesson.getTeacher() == rightLesson.getTeacher() &amp;amp;&amp; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) The cancelled lessons are no longer coming in from the left, which reduces the cross product. However, some cancelled lessons are still coming in from the right through the join. Here, we will use a little trick and join not with a Lesson class, but with a filtered nested Constraint Stream instead: constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()) .join( constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled())) .filter((leftLesson, rightLesson) -&gt; leftLesson.getTeacher() == rightLesson.getTeacher() &amp;amp;&amp; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) As you can see, we’ve created a new Constraint Stream from Lesson, filtering before it entered our join. We have now applied the same improvement on both the left and right sides of the join, making sure it only creates a cross product of lessons which we care about. But we can still do better! PREFER JOINERS TO FILTERS Filters are just a simple check if a tuple matches a predicate. If it does, it is sent downstream, otherwise the tuple is removed from the Constraint Stream. Each tuple needs to go through this check, and that means every pair of lessons will be evaluated. When a Lesson changes, all pairs with that Lesson will be re-evaluated, but not anymore: constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()) .join( constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()), Joiners.equal(Lesson::getTeacher)) .filter((leftLesson, rightLesson) -&gt; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) Notice that the Teacher equality check moved from the final filter to something called a Joiner. We are still saying the same thing – a Lesson pair will only be sent downstream if the Lessons share the same Teacher. Unlike the filter, this brings the performance benefit of indexing. Now when a Lesson changes, only the pairs with the matching Teacher will be re-evaluated. So even though the cross-product remains the same, we are doing much less work processing it. The final filter now only performs one operation on the final cross product, and the Lesson pairs that get this far are already trimmed down in the most efficient way possible. REMOVE MORE, EARLIER In some cases, you may have an option to pick the order of your Joiners. In these situations, you should put first the Joiner that will remove more tuples than the others. This will reduce the size of your cross products faster. Consider a new situation, where lessons also have rooms in which they happen. Although there are possibly dozens of teachers, there are only three rooms. Therefore the join should look like this: constraintFactory.from(Lesson.class) .join(Lesson.class, Joiners.equal(Lesson::getTeacher), Joiners.equal(Lesson::getRoom)) ... This way, we first create “buckets” for each of the many teachers, and these buckets will only contain a relatively small number of lessons per room. If we did it the other way around, there would be a small amount of large buckets, leading to much more iteration every time a lesson changes. For that reason, it is generally recommended putting Joiners based on enum fields or boolean fields last. CONCLUSION The key to efficient constraints is the reduction of cross product. There are three main ways of reducing cross product in Constraint Streams: 1. Filtering before joining. 2. Preferring Joiners earlier to filtering later. 3. Applying the more restrictive Joiners first. There are other optimization techniques as well, and we will discuss some of them in the future, but none of them will give as big a benefit as reducing the size of cross products. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/eaW922tbOWw" height="1" width="1" alt=""/&gt;</content><dc:creator>triceo</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/writing-fast-constraints-with-optaplanner-the-secret-recipe.html</feedburner:origLink></entry><entry><title type="html">Tooling guide for Getting Started with Apache Camel in 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/CugRKVT82PY/tooling-guide-for-getting-started-with.html" /><author><name>CHRISTINA の J老闆</name></author><id>http://feedproxy.google.com/~r/blogspot/hFXzh/~3/N9sx2zTVps4/tooling-guide-for-getting-started-with.html</id><updated>2021-05-26T13:20:00Z</updated><content type="html">Getting Started with Apache Camel ? This post is for you. But I am not going to dive into how to write the Camel route, there are plenty of materials out there that do a better job than me. A good place to get started is the one and only , it gives you all the latest and greatest news from the community. If you want to start from the basics, I highly recommend Camel in Action II Book. It has everything you need to know about writing Camel. Or join the Camel community or chat  to ask questions, it's very friendly and welcoming. If you are a returning Camel rider, I would go through this , where it will get you up to speed on what to expect.  Another good resource is the page. I found the majority of the getting started enquiries can be found here.  This post will be about tools that can help you, when it comes to running a Camel application in its lifetime. From design, implementation, testing, deployment and monitoring. Of course this is strictly my opinion. Any suggestions or comments are welcome. Here is a quick collection of the tools I recommend.  DESIGN &amp;amp; IMPLEMENTATION There are several different IDEs out there that have language support for Camel. My current goto is the . VS Code itself has very primitive support for Java developers, but it comes with a large variety of extensions for you to customize it, and install all the tools you need. Speaking of extension, there is a must have… “”. It contains the essentials for developing Camel. I recommend checking out the for updates!  To begin a project, it’s always good to have some help to set the basic structure. You can either use the Project Initializer that comes with the Apache Camel by Red Hat Extension in VS Code that will generate the base project for you. Or you can always go to the Quarkus start coding page, adding the Camel dependencies to create the base project, but one downside of the Quarkus start coding page, it will not create the template extended RouteBuilder class for you.  No matter what runtime you choose, you are still writing Camel DSL (Domain Specific Language), you have the latest and greatest support from the camel extension, where it will help you with autocomplete, validating your Camel code.   Mapping data between formats can be tedious, especially with larger documents or more complex structure. But using the tooling can help you map between two data sources with a drag and drop user interface, so you will be able to visualize the mappings. The tool will generate an “.adm” file, place the file into your Camel project. You can then use the camel-atlasmap components to run the mapping.   from("servicenow:xxxxxx....")   .split().body()     .marshal().json()     .to("atlasmap:servicenow.adm")     .to("kafka:xxx?brokersxxx") RESTful API is another popular implementation in Camel, I highly recommend you take advantage of the Apicurio project, where it provides a GUI interface for designing the API contract. Making contract first application development a lot easier. For more details, take a look at my previous .  Another nice complements to the toolset is the , this is another extension in VS Code by Bruno, this can help you visualize the design of camel processing flow. So you will be able to see what your camel route does in a quick glance. TESTING  Camel can easily wire up unit tests in your preferred testing framework. My past experience has been great with using JUnit for creating my test cases.   What I normally would do is create a java Class for each test case (Extend “CamelTestSupport” class). Where it can kick off your camel route with mock endpoints, loading set of data or even stub out the actual endpoint When testing integration, introducing Behavior-Driven Development(BDD) Testing is a development practice, as it’s black box testing nature allows it to better mimic user input and expectation, and can test more complex scenarios when compared to Test-Driven Development(TDD). Consider using the “” for building out BDD test cases. You can define the test scenario descriptions with a "Given-When-Then" structure in a feature file, as well as a simple setup for mimicking the common endpoints such as Kafka, AMQP, JMS, REST… etc.   Feature: integration runs   Background:     Given load variables namespace.properties     Given URL: http://camel-hello-quarkus.${namespace}.svc.cluster.local:8080   Scenario: Checking GET Method     When send GET /prescription?profileid=123456     Then verify HTTP response body: {"profileid": 123456, "pharmancy": "CVS" }     Then receive HTTP 200 OK I have also been using a spinoff project from Citrus called YAKs to do my BDD testing on Kubernetes(OpenShift) platform. And I LOVED it. Simply because 1st, the lifecycle of the test was managed by the YAKs operator, meaning the test was run on a separate instance, that is where the client supposed the call, and also the YAKs operator takes in the feature, and does the test based on it. You can run it separately or plug it into your CI/CD pipeline. PLATFORM I have been using for managing all the running instances. It's just easier when there are hundreds of Camels running, it manages the scaling, resources, configuration and load-balancing for me. As well as a better deployment module (images). There are so many articles out there talking about the benefits of running a container &amp;amp; container management, so I won’t dive into it.  CI/CD Jenkin was on my list for a long time when it comes to building the pipeline for my Camel application. Basically using the maven jenkins plugin for compiling and deploying, and using the OpenShift plugin to do the canary releases. And recently, I have been using the Tekton pipeline, it’s built-in on OpenShift, so there is no need to install a separate instance and manage it. The Kubernetes platform itself will become the CI/CD platform itself. Here is an example of how it works with the Camel projects. I will write another deep dive into how it works. MONITORING With Camel 3, in order to collect and export the metrics, you will need to specifically add the microprofile-metrics dependency. And by using Prometheus to scrape metrics on the platform. It stores all scraped samples locally and aggregate the time series data. I then use Grafana to visualize the collected data, and create a dashboard to monitor all the camel routes. Also checkout this video and see how things work:&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/CugRKVT82PY" height="1" width="1" alt=""/&gt;</content><dc:creator>CHRISTINA の J老闆</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/blogspot/hFXzh/~3/N9sx2zTVps4/tooling-guide-for-getting-started-with.html</feedburner:origLink></entry><entry><title type="html">JGroups 5.1.7 released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_xduhFXat4o/jgroups-517-released.html" /><author><name>Bela Ban</name></author><id>http://belaban.blogspot.com/2021/05/jgroups-517-released.html</id><updated>2021-05-26T08:06:00Z</updated><content type="html">I'm happy to announce that 5.1.7 has been released! The major new features are FD_SOCK2 [1] and VERIFY_SUSPECT2 [2]. The complete list of features and bug fixes is at [4]. Here's a short description of the major changes/additions: FD_SOCK2 This is a rewrite of FD_SOCK, which was created 20 (!) years ago. The old protocol has worked surprisingly well, given its brittle and complex design. FD_SOCK2 should be much more robust, as I've eliminated the cache between ports and members, and code which maintains this cache. Also, FD_SOCK2 (re-)uses NioServer, which means that we'll use 1 (select) thread instead of 3 in FD_SOCK. Compared to FD_SOCK's 1235 LOC, FD_SOCK2 has 723 LOC with the same functionality. VERIFY_SUSPECT2 The major change over VERIFY_SUSPECT is that VERIFY_SUSPECT2 bundles SUSPECT events sent up the stack. This reduces the where view installation runs into a timeout waiting for acks from crashed members. When X crashed, and then Y crashed a few milliseconds later, then VERIFY_SUSPECT would have sent up events SUSPECT(X) and then SUSPECT(Y), whereas VERIFY_SUSPECT2 sends up SUSPECT(X,Y) *if* X and Y crashed in the same time window (1s by default). This speeds up the installation of the new view, especially when multiple members have crashed. NO NEED TO USE JMX= OR OP= IN PROBE This is only syntatic sugar, but now we can shorten probe.sh jmx=UDP.bind to probe.sh UDP.ping and probe.sh op=TCP.printConnections to probe.sh TC.printConnections[]. This comes in handy when switching between attributes and operations. JIRA: [3] [1] [2] [3] [4]&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_xduhFXat4o" height="1" width="1" alt=""/&gt;</content><dc:creator>Bela Ban</dc:creator><feedburner:origLink>http://belaban.blogspot.com/2021/05/jgroups-517-released.html</feedburner:origLink></entry><entry><title>Real-time debugging in Tekton pipelines</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PLrlPxyOTfA/real-time-debugging-tekton-pipelines" /><author><name>Vibhav Bobade</name></author><id>f773e1ba-caea-4edd-8bc7-9b838c035aab</id><updated>2021-05-26T07:00:00Z</updated><published>2021-05-26T07:00:00Z</published><summary type="html">&lt;p&gt;Debugging &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;CI/CD&lt;/a&gt; pipelines isn't always easy. This is especially true when a pipeline takes a long time to run, and the failing part you want to debug runs at the end of the pipeline. A feature introduced in a recent &lt;a href="https://tekton.dev/"&gt;Tekton&lt;/a&gt; enhancement proposal (TEP) would let users stop the pipeline at any Step and debug in real time.&lt;/p&gt; &lt;p&gt;This article looks at debugging TaskRuns in Tekton, the open source framework that integrates with &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; to create cloud-native CI/CD pipelines. You can learn more about the basics of Tekton in &lt;a href="https://developers.redhat.com/blog/2020/04/30/creating-pipelines-with-openshift-4-4s-new-pipeline-builder-and-tekton-pipelines/"&gt;this article by Joel Lord&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The proposal, &lt;a href="https://github.com/tektoncd/community/blob/main/teps/0042-taskrun-breakpoint-on-failure.md"&gt;TEP-0042&lt;/a&gt;, outlines this feature with a proof of concept that describes how Tekton's composability and &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container support&lt;/a&gt; enable this functionality. For a thorough overview of these concepts, watch the talk, &lt;a href="https://www.youtube.com/watch?v=iz9_omZ0ctk"&gt;Russian Doll: Extending Containers with Nested Processes&lt;/a&gt; by Christie Wilson (Google) and Jason Hall (Red Hat).&lt;/p&gt; &lt;h2&gt;Debugging TaskRuns: TL;DR&lt;/h2&gt; &lt;p&gt;Debugging TaskRuns in Tekton is possible because of the composability provided by container-based pipelines it helps the user create. A Task runs as a Pod, and each Step in a Task runs in a container. With each Step running in a container, we can be sure that the delta of change in the container environment (which is not shared between Steps) is directly associated with the Step itself and nothing else. Anything else that might happen is a side effect, e.g., due to the injection of a sidecar container to the TaskRun. This makes Tekton great for debugging pipelines, as the cost to spin up a container is definitely far less than spinning up a cloud virtual machine (VM).&lt;/p&gt; &lt;p&gt;With this in mind, TEP-0042 would extend the TaskRun Step life cycle (responsible for orchestrating TaskRun containers to run serially) and add capabilities to pause a TaskRun Step after a failure occurs.&lt;/p&gt; &lt;h2&gt;Modifying the life of a Step&lt;/h2&gt; &lt;p&gt;The life of a Step currently looks something like Figure 1.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/Screenshot-from-2021-04-28-13-14-36.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/Screenshot-from-2021-04-28-13-14-36.png?itok=Cqwq_4AJ" width="516" height="466" alt="Diagram showing the life of a Step in Tekton: e.Go(), Wait for postFile, write err postFile, return err, exit." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The life of a Step in Tekton.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The Step starts running when &lt;code&gt;e.Go()&lt;/code&gt; runs. This is where Tekton invokes the entry point of the Step in the TaskRun and the child process (which is the actual Step) runs. If the child process runs successfully, we write a &lt;code&gt;postFile&lt;/code&gt; that is used as a flag to convey the same. If it fails, we write an &lt;code&gt;err postFile&lt;/code&gt;, which conveys a similar message.&lt;/p&gt; &lt;p&gt;To halt this Step on failure, we must understand which parts of the Step react when the failure occurs; this is the &lt;code&gt;write err postFile&lt;/code&gt; and &lt;code&gt;exit&lt;/code&gt; shown in Figure 1. When a Step fails, the failure is marked by writing a &lt;code&gt;&lt;step-no&gt;.err&lt;/code&gt; file to &lt;code&gt;/tekton/tools/&lt;/code&gt; directory in the Step container, which is shared with other containers in the Pod. This file is written by the background job in the entry point. The &lt;code&gt;&lt;step-no&gt;.err&lt;/code&gt; file also lets the subsequent Steps know that there has been a failure, and eventually exits the TaskRun.&lt;/p&gt; &lt;p&gt;This mechanism needs to be updated to support the discovery of Step failures and the ability to stop the Steps before it exits. This requires disabling the &lt;code&gt;write err postFile&lt;/code&gt;. Instead of exiting the Step, it will wait for a flag that would exit the Step from the suspended state. The updated flow would look something like the diagram shown in Figure 2.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/Screenshot-from-2021-04-28-13-24-40.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/Screenshot-from-2021-04-28-13-24-40.png?itok=MyFfl93M" width="505" height="440" alt="Diagram showing proposed Step life cycle in Tekton when TaskRun failure occurs: e.Go(), Wait for postFile, return err, Wait for breakpoint exit." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The proposed update to the Step life cycle in Tekton when TaskRun failure occurs.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once the Step is halted, the client can access the container environment for debugging.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In practice, the debugging solution is more nuanced than the overview provided here. Read &lt;a href="https://github.com/tektoncd/community/blob/main/teps/0042-taskrun-breakpoint-on-failure.md"&gt;the full TEP-0042 proposal&lt;/a&gt; for details.&lt;/p&gt; &lt;p&gt;This topic is also the subject of a cdCon 2021 talk: &lt;a href="https://cdcon2021.sched.com/event/iotA/houston-weve-got-a-problem-how-to-debug-your-pipeline-in-tekton-in-realtime-vibhav-bobade-vincent-demeester-red-hat"&gt;Houston, We've Got a Problem!: How to Debug your Pipeline in Tekton&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The debugging feature is expected to be available in Tekton later this year, with support across different Tekton clients, including the &lt;a href="https://github.com/openshift/pipelines-tutorial"&gt;Red Hat OpenShift Pipelines&lt;/a&gt; command-line interface (&lt;code&gt;tkn&lt;/code&gt;) and the Tekton dashboard. Get ready to debug Tekton pipelines in real time.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/26/real-time-debugging-tekton-pipelines" title="Real-time debugging in Tekton pipelines"&gt;Real-time debugging in Tekton pipelines&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PLrlPxyOTfA" height="1" width="1" alt=""/&gt;</summary><dc:creator>Vibhav Bobade</dc:creator><dc:date>2021-05-26T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/26/real-time-debugging-tekton-pipelines</feedburner:origLink></entry><entry><title type="html">Getting started with TrustyAI in only 15 minutes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/0i1ugm-hPb4/getting-started-with-trustyai-in-only-15-minutes.html" /><author><name>Jacopo Rota</name></author><id>https://blog.kie.org/2021/05/getting-started-with-trustyai-in-only-15-minutes.html</id><updated>2021-05-26T06:32:57Z</updated><content type="html">Hi Kogito folks, In the previous blogposts we demonstrated how to deploy a Kogito service together with the TrustyAI infrastructure on an OpenShift cluster . If you are new to TrustyAI, we suggest you read this introduction: In this blogpost, we’d like to demonstrate how to get started with TrustyAI in ~15 minutes. In order to start the demo, you will need the following applications installed on your laptop git &gt;= 2.27.0 docker &gt;= 20.10.3 docker-compose &gt;= 1.25.2 java &gt;= 11 maven &gt;= 3.6.3 Note that also previous versions of the applications might work, but they were not tested. The first step is to clone our kogito-examples repository (if you haven’t it yet) with git clone https://github.com/kiegroup/kogito-examples.git and checkout the stable branch cd kogito-examples git checkout stable and build a Kogito decision service with the tracing-addon and the monitoring-addon. For example kogito-examples/dmn-tracing-quarkus is already prepared, so you can compile and package it with mvn clean package -DskipTests -f dmn-tracing-quarkus/pom.xml and then copy the generated grafana dashboards to the docker-compose directory with cp dmn-tracing-quarkus/target/classes/META-INF/resources/monitoring/dashboards/* trusty-demonstration/docker-compose/grafana/provisioning/dashboards/ and then build the docker image with docker build -t org.kie.kogito/dmn-tracing-quarkus:1.0 dmn-tracing-quarkus/ In this example we tag the image org.kie.kogito/dmn-tracing-quarkus:1.0, but you can use another tag. The second step is to run the Kogito service together with the TrustyAI infrastructure. In order to do that, change your current directory to kogito-examples/trusty-demontration/docker-compose . With your preferred editor, edit the file docker-compose.yaml and replace the line 48 with the tag of the docker image you have just created (we used org.kie.kogito/dmn-tracing-quarkus:1.0 for example) The final step is just about running the docker-compose script with (depending on your setup, you might need to run this command with sudo ) docker-compose up The services are available at the following endpoints: * Kogito application: localhost:8080 * AuditUI: localhost:1337 * Grafana: localhost:3000 You can now open localhost:8080/swagger-ui and execute some POST requests to the LoanEligibility with the following payload { "Bribe": 1000, "Client": { "age": 43, "existing payments": 100, "salary": 1950 }, "Loan": { "duration": 15, "installment": 180 }, "SupremeDirector": "Yes" } You should now see the executions in the AuditUI and the monitoring data in Grafana. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/0i1ugm-hPb4" height="1" width="1" alt=""/&gt;</content><dc:creator>Jacopo Rota</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/getting-started-with-trustyai-in-only-15-minutes.html</feedburner:origLink></entry><entry><title type="html">Quarkus 1.13.5.Final released - Maintenance release</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/dNlmPatTwes/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-13-5-final-released/</id><updated>2021-05-26T00:00:00Z</updated><content type="html">We released 1.13.5.Final today with a new set of bugfixes for our 1.13 release. 1.13.5.Final is a safe upgrade for everyone using Quarkus 1.13. If you are not using 1.13 already, please refer to the 1.13 migration guide. What’s new? Maven 3.8.1 Given there are a couple of CVEs in...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/dNlmPatTwes" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-13-5-final-released/</feedburner:origLink></entry></feed>
